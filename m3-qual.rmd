# Initialize
## Set Options
```{r purl = TRUE}
# Toggle purl = FALSE to run model-nowcasts-backtest.rmd and purl = TRUE to run windows task scheduler
DIR = 'D:/Onedrive/__Projects/econforecasting'
M2_PATH = 'D:/Onedrive/__Projects/econforecasting/model-outputs/[2021-08-15] m2.rds'
PACKAGE_DIR = 'D:/Onedrive/__Projects/econforecasting/r-package' # Path to package with helper functions
INPUT_DIR = 'D:/Onedrive/__Projects/econforecasting/model-inputs' # Path to directory with constants.r (SQL DB info, SFTP info, etc.)
OUTPUT_DIR = 'D:/Onedrive/__Projects/econforecasting/model-outputs'
```

# Initialize
```{r}
# General purpose
library(tidyverse) # General
library(data.table) # General
library(devtools) # General
library(lubridate) # Dates
library(glue) # String Interpolation
# Data parse/import
library(jsonlite) # JSON Parser
library(rvest) # HTML Parser
library(httr) # CURL Interface
# SQL/Apache Spark
library(DBI) # SQL Interface
# library(RPostgres) # PostgreSQL
# library(rsparklyr) # Spark
# My package
devtools::load_all(path = PACKAGE_DIR)
devtools::document(PACKAGE_DIR)
# library(econforecasting)

# Set working directory
setwd(DIR)

# Read constants
source(file.path(INPUT_DIR, 'constants.r'))
```

## Load RDS
```{r}
local({
	
	rds = readRDS(M2_PATH)

	p <<- rds$p
	m <<- rds$m
	h <<- rds$h
})
```



# Generate Initial Forecasts

## CMEFI baseline forecasts (qual)
Display in website those variables not taken from "external" source - e.g. unemp
```{r}
local({

    baseline = list()
    
    # ffr, sofr, inf, tdns1, tdns2, tdns3, pid, ue, hpi
    baseline$ffr =
        m$ext$sources$cme %>%
        dplyr::filter(., varname == 'ffr') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$ffr$h$base$m$date)) %>%
        dplyr::transmute(., freq, form, date, value)
    
    baseline$sofr =
        m$ext$sources$cme %>%
        dplyr::filter(., varname == 'sofr') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$sofr$h$base$m$date)) %>%
        dplyr::transmute(., freq, form, date, value)
    
    baseline$inf =
        m$ext$sources$cle %>%
        dplyr::filter(., varname == 'inf') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$inf$h$base$m$date)) %>%
        dplyr::transmute(., freq, form, date, value)
    
    baseline$tdns1 =
        m$ext$sources$dns %>%
        dplyr::filter(., varname == 'tdns1') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$tdns1$h$base$m$date)) %>%
        dplyr::transmute(., freq, form, date, value)
    
    baseline$tdns2 =
        m$ext$sources$dns %>%
        dplyr::filter(., varname == 'tdns2') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$tdns2$h$base$m$date)) %>%
        dplyr::transmute(., freq, form, date, value)
    
    baseline$tdns3 =
        m$ext$sources$dns %>%
        dplyr::filter(., varname == 'tdns3') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$tdns3$h$base$m$date)) %>%
        dplyr::transmute(., freq, form, date, value)

    
    # Use nowcast -> slice with moving average
    baseline$pid =
		m$ncpred$d1$m[, c('date', 'pid')] %>%
    	na.omit(.) %>%
    	dplyr::rename(., value = 'pid') %>%
    	dplyr::transmute(., date, value) %>%
    	# Only take first row from nowcast and replace with 1
    	head(., 1) %>%
    	dplyr::mutate(., value = ifelse(date == min(date), 8.0, value)) %>%
        dplyr::bind_rows(
            .,
            tribble(
            	~ 'date', ~ 'value',
            	as.Date('2022-04-01'), 5.00,
            	as.Date('2022-07-01'), 5.00,
            	as.Date('2023-10-01'), 3.50,
            	tail(baseline$ffr$date, 1), 2.80
            )
        ) %>%
    	dplyr::left_join(
    		tibble(date = seq(from = min(.$date), to = max(.$date), by = '1 month')),
    		.,
    		by = 'date'
    	) %>%
    	dplyr::mutate(., value = zoo::na.approx(value), form = 'd1', freq = 'm')

    
    # Display in website
    baseline$ue =
        # Take last four quarters of historical data
        p$variables$ue$h$base$m %>%
        tail(., 4) %>%
        dplyr::transmute(., form = 'd1', date, value) %>%
        # Bind next 24 months
        dplyr::bind_rows(
            .,
            tibble(
                form = 'd1',
                date = seq(from = lubridate::add_with_rollback(tail(.$date, 1), months(1)), by = '1 month', length.out = 60)
                )
            ) %>%
        # Now join with external forecast, but use historical data if external forecast has same dates
        dplyr::left_join(
            .,
            m$ext$sources$spf %>%
                dplyr::filter(., vdate == max(vdate) & varname == 'ue') %>%
                dplyr::transmute(., form, date, value2 = value),
            by = c('form', 'date')
        ) %>%
        dplyr::mutate(., value = ifelse(!is.na(value), value, value2)) %>%
        # Add in long run average
        dplyr::mutate(., value = ifelse(date == max(date), 5.0, value)) %>%
        # Splinal interpolate
        dplyr::mutate(., value = zoo::na.spline(value, method = 'natural')) %>%
        tail(., -4) %>%
    	dplyr::select(., -value2) %>%
    	dplyr::mutate(., freq = 'm')
    
    baseline$hpi =
		m$ncpred$d1$m[, c('date', 'hpi')] %>%
    	na.omit(.) %>%
    	dplyr::rename(., value = 'hpi') %>%
    	dplyr::transmute(., date, value) %>%
        dplyr::bind_rows(
            .,
            tribble(
            	~ 'date', ~ 'value',
            	as.Date('2022-04-01'), 3.50,
            	as.Date('2022-07-01'), 3.00,
            	as.Date('2023-10-01'), 2.50,
            	tail(baseline$ffr$date, 1), 2.80
            )
        ) %>%
    	dplyr::left_join(
    		tibble(date = seq(from = min(.$date), to = max(.$date), by = '1 month')),
    		.,
    		by = 'date'
    	) %>%
    	dplyr::mutate(., value = zoo::na.approx(value), form = 'd1') %>%
    	dplyr::mutate(., freq = 'm')
    
    
    baseline$spy =
		m$ncpred$d1$m[, c('date', 'spy')] %>%
    	na.omit(.) %>%
    	dplyr::rename(., value = 'spy') %>%
    	dplyr::transmute(., date, value) %>%
        dplyr::bind_rows(
            .,
            tribble(
            	~ 'date', ~ 'value',
            	as.Date('2023-04-01'), 1.00,
            	as.Date('2024-04-01'), 1.00,
            	as.Date('2025-04-01'), 0.90,
            	as.Date('2026-04-01'), 0.90
            )
        ) %>%
    	dplyr::left_join(
    		tibble(date = seq(from = min(.$date), to = max(.$date), by = '1 month')),
    		.,
    		by = 'date'
    	) %>%
    	dplyr::mutate(., value = zoo::na.approx(value), form = 'd1') %>%
    	dplyr::mutate(., freq = 'm')

    # Direction of spread is almost always exactly in the opposite direction of t10y/2
	# dplyr::inner_join(p$variables$mort15yt10yspread$h$d1$m, p$variables$t10y$h$d1$m, by = 'date') %>%
	# ggplot(.) + geom_line(aes(x = date, y = value.x)) + geom_line(aes(x = date, y = value.y))
    
    baseline$mort15yt10yspread =
    	# Get change in tdns1
    	dplyr::bind_rows(
    		p$variables$tdns1$h$d1$m,
    		baseline$tdns1 %>% dplyr::select(., -form)
    		) %>%
    	dplyr::mutate(., value = (value - dplyr::lag(value, 1))) %>%
    	# Scale to appropriate change desired in mort15y10yspread
    	dplyr::mutate(., value = value * -1/4) %>%
    	# Now undifference to get forecast for mortspread
    	dplyr::filter(., date > max(p$variables$mort15yt10yspread$h$d1$m$date)) %>%
    	dplyr::mutate(., value = undiff(value, 1, tail(p$variables$mort15yt10yspread$h$d1$m, 1)$value), form = 'd1') %>%
    	dplyr::mutate(., freq = 'm')
    
    
    baseline$mort30yt30yspread =
    	# Get change in tdns1
    	dplyr::bind_rows(
    		p$variables$tdns1$h$d1$m,
    		baseline$tdns1 %>% dplyr::select(., -form)
    		) %>%
    	dplyr::mutate(., value = (value - dplyr::lag(value, 1))) %>%
    	# Scale to appropriate change desired in mort15y10yspread
    	dplyr::mutate(., value = value * -1/4) %>%
    	# Now undifference to get forecast for mortspread
    	dplyr::filter(., date > max(p$variables$mort30yt30yspread$h$d1$m$date)) %>%
    	dplyr::mutate(., value = undiff(value, 1, tail(p$variables$mort30yt30yspread$h$d1$m, 1)$value), form = 'd1') %>%
    	dplyr::mutate(., freq = 'm')

    
    # Have first four quarters of PCE, gross_pdi, etc. be exogenous in data
    ncList = c(
    	'pcegdmotor', 'pcegdfurnish', 'pcegdrec', 'pcegdother',
    	'pcegnfood', 'pcegnclothing', 'pcegngas', 'pcegnother',
    	'pceshousing', 'pceshealth', 'pcestransport', 'pcesrec', 'pcesfood', 'pcesfinal',
    	'pcesother', 'pcesnonprofit', 'pdinstruct', 'pdinequip', 'pdinip',
    	'exg', 'exs', 'img', 'ims', 'govt', 'govts'
    	)
    
    ncForecasts =
    	m$ncpredFlat %>%
    	dplyr::filter(., freq == 'q' & varname %in% ncList & form == 'd1' & vdate == max(vdate)) %>%
    	dplyr::group_by(., varname) %>%
    	econforecasting::namedSplit(.) %>%
    	lapply(., function(df)
    		df %>%
    			dplyr::select(., freq, form, date, value)
    		)

    if (all(sort(names(ncForecasts)) != sort(ncList))) stop('Error: missing nowcasted variable')
    baseline = c(
    	baseline,
    	ncForecasts
    )

    m$qual$predraw$baseline <<- baseline
})
```

## Other scenario forecasts (qual)
```{r}
local({
	
	# upside = list()
	# 
	# upside$ffr =
	# 	m$qual$predraw$baseline$ffr %>%
		
	
	
    
})
```

# Transforms

## Detransform to Base Form
```{r}
local({
	
	res = purrr::imap(m$qual$predraw, function(x, .scenarioname) {
			
		purrr::imap(x, function(df, .varname) {
			
			.freq = df$freq[[1]]
			transform = dplyr::filter(p$variablesDf, varname == .varname)[[df$form[[1]]]]
			fcDf = dplyr::select(df, -form)
			histDf =
				h$flat %>%
				dplyr::filter(., varname == .varname, date < min(fcDf$date), freq == .freq) %>%
				tail(., 1) %>%
				dplyr::select(., freq, date, value)
				
			fcDf %>%
				dplyr::mutate(
					.,
					varname = .varname,
					value := {
                        if (transform == 'dlog') undlog(fcDf$value, histDf$value)
						else if (transform == 'apchg') unapchg(fcDf$value, {if (.freq == 'm') 12 else 4}, histDf$value)
						else if (transform == 'pchg') unpchg(fcDf$value, histDf$value)
						else if (transform == 'base') .$value
						else stop('Err: ', .varname)
						}
					)
				}) %>%
			dplyr::bind_rows(.)
		})
	
	
	m$qual$predqual <<- res
})
```

## Add calculated variables
```{r}
local({
	
	# Calculate DNS
	lambda = m$dnsLambda
	
	# Rebuild yield curves with Diebold-Li function
	df =
		lapply(m$qual$predqual, function(df) {
			
			scenario =
				m$qual$predqual[[1]] %>% dplyr::filter(., freq == 'm') %>%
				dplyr::select(., -freq) %>%
				tidyr::pivot_wider(., names_from = 'varname', values_from = 'value') %>%
				dplyr::arrange(., date)
			
			tDf = lapply(purrr::transpose(m$dnsYieldCurveNamesMap), function(y)
					scenario %>%
						dplyr::transmute(
							.,
							date,
							!!y$varname := ffr +
								tdns1 +
								tdns2 * (1-exp(-1 * lambda * y$ttm))/(lambda * y$ttm) +
								tdns3 * ((1-exp(-1 * lambda * y$ttm))/(lambda * y$ttm) - exp(-1 * lambda * y$ttm))
							)
					) %>%
				purrr::reduce(., function(x, y) dplyr::inner_join(x, y, by = 'date'))
			
			mortDf =
				dplyr::inner_join(scenario, tDf, by = 'date') %>%
				{lapply(colnames(.) %>% .[. != 'date'], function(.varname) {
					dplyr::select(., all_of(c('date', .varname))) %>%
						na.omit(.) %>%
						dplyr::bind_rows(
							filter(na.omit(h$base$m[, c('date', .varname)]), date <= tail(.$date[[1]])),
							.
						)
				})} %>%
				purrr::reduce(., function(x, y) dplyr::full_join(x, y, by = 'date')) %>%
				dplyr::arrange(., date) %>%
				dplyr::transmute(., date, mort15y = mort15yt10yspread + t10y, mort30y = mort30yt30yspread + t30y) %>%
				{lapply(colnames(.) %>% .[. != 'date'], function(.varname) {
					dplyr::select(., all_of(c('date', .varname))) %>%
						dplyr::filter(., date >= tail(na.omit(h$base$m[, c('date', .varname)])$date, 1))
				})} %>%
				purrr::reduce(., function(x, y) dplyr::full_join(x, y, by = 'date')) %>%
				dplyr::arrange(., date)

			list(tDf, mortDf) %>%
				purrr::reduce(., function(x, y) dplyr::full_join(x, y, by = 'date')) %>%
				dplyr::arrange(., date)
			})

	
	m$qual$predcalcM <<- df
})
```


## Add quarterly calculated
```{r}
local({
	
	# Rebuild yield curves with Diebold-Li function
	df =
		lapply(m$qual$predqual, function(df) {
			
			scenario =
				m$qual$predqual[[1]] %>% dplyr::filter(., freq == 'q') %>%
				dplyr::select(., -freq) %>%
				tidyr::pivot_wider(., names_from = 'varname', values_from = 'value') %>%
				dplyr::arrange(., date)
			
			scenario %>%
				dplyr::transmute(
					.,
					date
				)
			})

	
	m$qual$predcalcQ <<- df
})
```


# Calculate monthly forecasts

## Get final monthly
```{r}
local({
	
	res = lapply(names(m$qual$predqual) %>% setNames(., .), function(.scenarioname) {
		
		dplyr::bind_rows(
			m$qual$predqual[[.scenarioname]] %>%
				dplyr::filter(., freq == 'm') %>%
				dplyr::select(., -freq),
			m$qual$predcalcM[[.scenarioname]] %>%
				tidyr::pivot_longer(., -date, names_to = 'varname', values_to = 'value', values_drop_na = TRUE)
			)
	})
	

	m$qual$predFinalM <<- res
})
```

## Transform monthly
```{r}
local({
	
	
	
	
})
```



# Calculate quarterly forecasts


## Get initial quarterly
```{r}
local({
	
	res = lapply(names(m$qual$predqual) %>% setNames(., .), function(.scenarioname) {
		
		dplyr::bind_rows(
			m$qual$predqual[[.scenarioname]] %>%
				dplyr::filter(., freq == 'q') %>%
				dplyr::select(., -freq)#,
			# m$qual$predcalcQ[[.scenarioname]] %>%
			# 	tidyr::pivot_longer(., -date, names_to = 'varname', values_to = 'value', values_drop_na = TRUE)
			)
	})
	
	m$qual$predInitialQ <<- res
})
```

## Aggregate monthly to quarterly
```{r}
local({
	
	# Get exogenous qualitative forecasts
	qualDfs = m$qual$predFinalM
	

	# Iterate through scenarios, combine and aggregate to quarterly
	aggDfs = lapply(qualDfs, function(qualDf) {
		
		# Get historical Df
		histDf =
			h$flat %>%
			dplyr::filter(., freq == 'm' & varname %in% unique(qualDf$varname) & form == 'base') %>%
			dplyr::select(., date, value, varname)
		
		res = lapply(unique(qualDf$varname), function(.varname) {

			hDf = histDf %>% dplyr::filter(., varname == .varname)
			qDf = qualDf %>% dplyr::filter(., varname == .varname)
			
			dplyr::bind_rows(hDf, qDf) %>%
				dplyr::arrange(., date) %>%
				dplyr::mutate(., strdate = paste0(year(date), 'Q', quarter(date))) %>%
				dplyr::group_by(., strdate) %>%
				dplyr::group_split(.) %>%
			    lapply(., function(y) {
			        if (nrow(y) >= 3) tibble(varname = y$varname[[1]], value = mean(y$value), strdate = y$strdate[[1]])
			        else if (nrow(y) < 3) NA
			        else stop('Error: qDf has same varname/date combination as hDf')
			    }) %>%
				purrr::keep(., function(x) is_tibble(x)) %>%
				dplyr::bind_rows(.) %>%
				dplyr::mutate(., date = econforecasting::strdateToDate(strdate)) %>%
				dplyr::select(., -strdate) %>%
				dplyr::arrange(., date) %>%
				dplyr::filter(., date >= lubridate::floor_date(qDf$date[[1]], unit = 'quarters'))
			}) %>%
			dplyr::bind_rows(.)
		
		return(res)
		})
	
	## Bind to existing quarterly forecasts
	qDfs = lapply(names(qualDfs) %>% setNames(., .), function(.scenarioname) {
		
		dplyr::bind_rows(
			aggDfs[[.scenarioname]],
			m$qual$predInitialQ[[.scenarioname]]
			) %>%
			tidyr::pivot_wider(., names_from = 'varname', values_from = 'value') %>%
			dplyr::arrange(., date) %>%
			tidyr::pivot_longer(., -date, names_to = 'varname', values_to = 'value', values_drop_na = TRUE)
	})


	m$qual$predFinalQ <<- qDfs
})
```


# Join

## Create flattened
```{r}

```

## Create wide forecasts
```{r}

```

## Evaluation
```{r}

```





## Join & Flatten 
```{r}
local({
	
	
	baseDfs =
		lapply(names(m$qual$predqual) %>% setNames(., .), function(scenarioname)
			dplyr::bind_rows(
				tidyr::pivot_longer(m$qual$predqual[[scenarioname]], -date, names_to = 'varname'),
				tidyr::pivot_longer(m$qual$predcalc[[scenarioname]], -date, names_to = 'varname')
				) %>%
				dplyr::bind_rows(.) %>%
				tidyr::pivot_wider(., names_from = 'varname', values_from = 'value') %>%
				dplyr::arrange(., date)
			)
	
	dfs =
		purrr::imap(baseDfs, function(scenarioDf, scenarioname)
			lapply(c('d1', 'st') %>% setNames(., .), function(.form)
				lapply(colnames(scenarioDf) %>% .[. != 'date'], function(.varname) {
						
						transform = dplyr::filter(p$variablesDf, varname == .varname)[[.form]]
						fcDf = dplyr::select(scenarioDf, all_of(c('date', .varname))) %>% na.omit(.)
						histDf = tail(dplyr::filter(na.omit(h$base$m[, c('date', .varname)]), date < min(fcDf$date)), 1)
						
						dplyr::bind_rows(histDf, fcDf) %>%
							dplyr::mutate(
								.,
								!!.varname := 
									{
				                        if (transform == 'dlog') dlog(.[[2]])
										else if (transform == 'apchg') apchg(.[[2]], 12)
										else if (transform == 'pchg') pchg(.[[2]])
										else if (transform == 'base') .[[2]]
										else if (transform == 'none') NA
										else stop('Err: ', .varname)
										}
									) %>% .[2:nrow(.),]
						
						}) %>%
					purrr::reduce(., function(x, y) dplyr::full_join(x, y, by = 'date')) %>%
					dplyr::arrange(., date)
			) %>%
			c(list(base = baseDfs[[scenarioname]]), .)
		) 
	
	
	predFlat =
		dfs %>%
		purrr::imap_dfr(., function(x, scenarioname)
			purrr::imap_dfr(x, function(y, form)
				y %>%
					tidyr::pivot_longer(., -date, names_to = 'varname', values_to = 'value') %>%
					dplyr::mutate(., form = form, scenarioname = scenarioname) %>%
					na.omit(.)
				)
			)
	

	m$qual$pred <<- dfs
	m$qual$predFlat <<- predFlat
})
```


# Quarterly

# Transform to Baseline
```{r}
local({
	
	
	
})
```

## Aggregate Inputs to Quarterly
```{r}
local({
	
	# Get historical forecasts
	histDf =
		h$flat %>%
		split(., .$varname)  %>%
		purrr::map_dfr(., function(x)
			# Get monthly data if it exists, quarterly otherwise
			x %>%
				{
					if ('m' %in% unique(x$freq)) dplyr::filter(., form == 'st' & freq == 'm')
					else dplyr::filter(., form == 'st' & freq == 'q')
				} %>%
				dplyr::transmute(., varname, freq, date, value)
			)

	
	# Get exogenous qualitative forecasts
	qualDf =
		m$qual$predFlat %>%
		dplyr::filter(., form == 'st') %>%
		dplyr::transmute(., scenarioname, varname, freq = 'm', date, value)
	

	# Iterate through scenarios, combine and aggregate to quarterly
	exogDfs =
		qualDf %>%
    	split(., .$scenarioname) %>%
		lapply(., function(x)
			dplyr::bind_rows(histDf, x) %>%
				dplyr::arrange(., varname, date) %>%
				dplyr::mutate(., strdate = paste0(year(date), 'Q', quarter(date))) %>%
				dplyr::group_by(., varname, strdate) %>%
				dplyr::group_split(.) %>%
				lapply(., function(y) {
					if (y$freq[[1]] == 'm' && nrow(y) >= 3) tibble(varname = y$varname[[1]], value = mean(y$value), strdate = y$strdate[[1]])
					else if (y$freq[[1]] == 'm' && nrow(y) < 3) NA
					else if (y$freq[[1]] == 'q') dplyr::select(y, varname, value, strdate)
					}) %>%
				purrr::keep(., function(x) is_tibble(x)) %>%
				dplyr::bind_rows(.) %>%
				dplyr::mutate(., date = econforecasting::strdateToDate(strdate)) %>%
				dplyr::select(., -strdate) %>%
				tidyr::pivot_wider(., names_from  = 'varname', values_from = 'value') %>%
				dplyr::arrange(., date) %>%
				dplyr::filter(., date >= as.Date('2010-01-01'))
			)

	
	exogFlat =
		exogDfs %>%
		purrr::imap_dfr(., function(x, i)
			tidyr::pivot_longer(x, -date, names_to = 'varname', values_to = 'value') %>%
				dplyr::mutate(., scenarioname = i) %>%
				na.omit(.)
		)

	
	m$csm$exogDfs0 <<- exogDfs
	m$csm$exogFlat0 <<- exogFlat
})
```


# Evaluation

## Evaluate Pred Qual
```{r}
local({
	
	predCharts =
		m$qual$predFlat %>%
		dplyr::filter(., form == 'd1') %>%
		dplyr::group_by(., varname) %>%
		dplyr::group_split(.) %>%
		setNames(., sapply(., function(x) x$varname[[1]])) %>%
		lapply(., function(x) {
			
			param =
				p$variablesDf %>%
				dplyr::filter(., varname == x$varname[[1]]) %>%
				as.list(.)
			
			histDf = dplyr::transmute(p$variables[[param$varname]]$h$d1$m, date, value, type = 'Historical Data')
			
			forecastDf =
				dplyr::bind_rows(tail(histDf, 1), x) %>%
				dplyr::transmute(., date, value, type = 'Forecast')
 
			dplyr::bind_rows(histDf, forecastDf) %>%
				ggplot(.) +
				geom_line(aes(x = date, y = value, color = type, linetype = type)) +
				scale_color_manual(
					values = c('Historical Data' = 'black', 'Forecast' = 'Red')
				) +
				scale_linetype_manual(
					values = c('Historical Data' = 'solid', 'Forecast' = 'solid')
				) +
				labs(title = param$fullname, x = NULL, y = param$units, color = NULL, linetype = NULL) +
				ggthemes::theme_fivethirtyeight()
			})
	
	print(predCharts)
	
	m$qual$predCharts <<- predCharts
})
```


# Finalize

## Export
```{r}
local({
  
    saveRDS(
    	list(p = p, h = h, m = m),
    	str_glue(OUTPUT_DIR, '/[{p$VINTAGE_DATE}] m3.rds')
    	)
    
})
```