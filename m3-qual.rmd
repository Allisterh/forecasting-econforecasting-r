# Initialize
## Set Options
```{r purl = TRUE}
# Toggle purl = FALSE to run model-nowcasts-backtest.rmd and purl = TRUE to run windows task scheduler
DIR = 'D:/Onedrive/__Projects/econforecasting'
M2_PATH = 'D:/Onedrive/__Projects/econforecasting/model-outputs/[2021-08-02] m2.rds'
PACKAGE_DIR = 'D:/Onedrive/__Projects/econforecasting/r-package' # Path to package with helper functions
INPUT_DIR = 'D:/Onedrive/__Projects/econforecasting/model-inputs' # Path to directory with constants.r (SQL DB info, SFTP info, etc.)
OUTPUT_DIR = 'D:/Onedrive/__Projects/econforecasting/model-outputs'
```

# Initialize
```{r}
# General purpose
library(tidyverse) # General
library(data.table) # General
library(devtools) # General
library(lubridate) # Dates
library(glue) # String Interpolation
# Data parse/import
library(jsonlite) # JSON Parser
library(rvest) # HTML Parser
library(httr) # CURL Interface
# SQL/Apache Spark
library(DBI) # SQL Interface
# library(RPostgres) # PostgreSQL
# library(rsparklyr) # Spark
# My package
devtools::load_all(path = PACKAGE_DIR)
devtools::document(PACKAGE_DIR)
# library(econforecasting)

# Set working directory
setwd(DIR)

# Read constants
source(file.path(INPUT_DIR, 'constants.r'))
```

## Load RDS
```{r}
local({
	
	rds = readRDS(M2_PATH)

	p <<- rds$p
	m <<- rds$m
	h <<- rds$h
})
```



# Generate Initial Forecasts

## CMEFI Baseline Forecasts (Qual)
Display in website those variables not taken from "external" source - e.g. unemp
```{r}
local({

    baseline = list()
    
    # ffr, sofr, inf, tdns1, tdns2, tdns3, pid, ue, hpi
    baseline$ffr =
        m$ext$sources$cme %>%
        dplyr::filter(., varname == 'ffr') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$ffr$h$base$m$date)) %>%
        dplyr::transmute(., form, date, value)
    
    baseline$sofr =
        m$ext$sources$cme %>%
        dplyr::filter(., varname == 'sofr') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$sofr$h$base$m$date)) %>%
        dplyr::transmute(., form, date, value)
    
    baseline$inf =
        m$ext$sources$cle %>%
        dplyr::filter(., varname == 'inf') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$inf$h$base$m$date)) %>%
        dplyr::transmute(., form, date, value)
    
    baseline$tdns1 =
        m$ext$sources$dns %>%
        dplyr::filter(., varname == 'tdns1') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$tdns1$h$base$m$date)) %>%
        dplyr::transmute(., form, date, value)
    
    baseline$tdns2 =
        m$ext$sources$dns %>%
        dplyr::filter(., varname == 'tdns2') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$tdns2$h$base$m$date)) %>%
        dplyr::transmute(., form, date, value)
    
    baseline$tdns3 =
        m$ext$sources$dns %>%
        dplyr::filter(., varname == 'tdns3') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$tdns3$h$base$m$date)) %>%
        dplyr::transmute(., form, date, value)

    
    # Use nowcast -> slice with moving average
    baseline$pid =
		m$ncpred$d1$m[, c('date', 'pid')] %>%
    	na.omit(.) %>%
    	dplyr::rename(., value = 'pid') %>%
    	dplyr::transmute(., date, value) %>%
        dplyr::bind_rows(
            .,
            tribble(
            	~ 'date', ~ 'value',
            	as.Date('2022-04-01'), 3.50,
            	as.Date('2022-07-01'), 3.00,
            	as.Date('2023-10-01'), 2.50,
            	tail(baseline$ffr$date, 1), 2.80
            )
        ) %>%
    	dplyr::left_join(
    		tibble(date = seq(from = min(.$date), to = max(.$date), by = '1 month')),
    		.,
    		by = 'date'
    	) %>%
    	dplyr::mutate(., value = zoo::na.approx(value), form = 'd1')

    
    # Display in website
    baseline$ue =
        # Take last four quarters of historical data
        p$variables$ue$h$base$m %>%
        tail(., 4) %>%
        dplyr::transmute(., form = 'd1', date, value) %>%
        # Bind next 24 months
        dplyr::bind_rows(
            .,
            tibble(
                form = 'd1',
                date = seq(from = lubridate::add_with_rollback(tail(.$date, 1), months(1)), by = '1 month', length.out = 60)
                )
            ) %>%
        # Now join with external forecast, but use historical data if external forecast has same dates
        dplyr::left_join(
            .,
            m$ext$sources$spf %>%
                dplyr::filter(., vdate == max(vdate) & varname == 'ue') %>%
                dplyr::transmute(., form, date, value2 = value),
            by = c('form', 'date')
        ) %>%
        dplyr::mutate(., value = ifelse(!is.na(value), value, value2)) %>%
        # Add in long run average
        dplyr::mutate(., value = ifelse(date == max(date), 5.0, value)) %>%
        # Splinal interpolate
        dplyr::mutate(., value = zoo::na.spline(value, method = 'natural')) %>%
        tail(., -4) %>%
    	dplyr::select(., -value2)
    
    baseline$hpi =
		m$ncpred$d1$m[, c('date', 'hpi')] %>%
    	na.omit(.) %>%
    	dplyr::rename(., value = 'hpi') %>%
    	dplyr::transmute(., date, value) %>%
        dplyr::bind_rows(
            .,
            tribble(
            	~ 'date', ~ 'value',
            	as.Date('2022-04-01'), 3.50,
            	as.Date('2022-07-01'), 3.00,
            	as.Date('2023-10-01'), 2.50,
            	tail(baseline$ffr$date, 1), 2.80
            )
        ) %>%
    	dplyr::left_join(
    		tibble(date = seq(from = min(.$date), to = max(.$date), by = '1 month')),
    		.,
    		by = 'date'
    	) %>%
    	dplyr::mutate(., value = zoo::na.approx(value), form = 'd1')
    
    
    baseline$spy =
		m$ncpred$d1$m[, c('date', 'spy')] %>%
    	na.omit(.) %>%
    	dplyr::rename(., value = 'spy') %>%
    	dplyr::transmute(., date, value) %>%
        dplyr::bind_rows(
            .,
            tribble(
            	~ 'date', ~ 'value',
            	as.Date('2023-04-01'), 1.00,
            	as.Date('2024-04-01'), 1.00,
            	as.Date('2025-04-01'), 0.90,
            	as.Date('2026-04-01'), 0.90
            )
        ) %>%
    	dplyr::left_join(
    		tibble(date = seq(from = min(.$date), to = max(.$date), by = '1 month')),
    		.,
    		by = 'date'
    	) %>%
    	dplyr::mutate(., value = zoo::na.approx(value), form = 'd1')

    # Direction of spread is almost always exactly in the opposite direction of t10y/2
	# dplyr::inner_join(p$variables$mort15yt10yspread$h$d1$m, p$variables$t10y$h$d1$m, by = 'date') %>%
	# ggplot(.) + geom_line(aes(x = date, y = value.x)) + geom_line(aes(x = date, y = value.y))
    
    baseline$mort15yt10yspread =
    	# Get change in tdns1
    	dplyr::bind_rows(
    		p$variables$tdns1$h$d1$m,
    		baseline$tdns1 %>% dplyr::select(., -form)
    		) %>%
    	dplyr::mutate(., value = (value - dplyr::lag(value, 1))) %>%
    	# Scale to appropriate change desired in mort15y10yspread
    	dplyr::mutate(., value = value * -1/4) %>%
    	# Now undifference to get forecast for mortspread
    	dplyr::filter(., date > max(p$variables$mort15yt10yspread$h$d1$m$date)) %>%
    	dplyr::mutate(., value = undiff(value, 1, tail(p$variables$mort15yt10yspread$h$d1$m, 1)$value), form = 'd1')
    
    
    baseline$mort30yt30yspread =
    	# Get change in tdns1
    	dplyr::bind_rows(
    		p$variables$tdns1$h$d1$m,
    		baseline$tdns1 %>% dplyr::select(., -form)
    		) %>%
    	dplyr::mutate(., value = (value - dplyr::lag(value, 1))) %>%
    	# Scale to appropriate change desired in mort15y10yspread
    	dplyr::mutate(., value = value * -1/4) %>%
    	# Now undifference to get forecast for mortspread
    	dplyr::filter(., date > max(p$variables$mort30yt30yspread$h$d1$m$date)) %>%
    	dplyr::mutate(., value = undiff(value, 1, tail(p$variables$mort30yt30yspread$h$d1$m, 1)$value), form = 'd1')

    m$qual$predraw$baseline <<- baseline
})
```

## Other Scenario Forecasts (Qual)
```{r}
local({
	
	# upside = list()
	# 
	# upside$ffr =
	# 	m$qual$predraw$baseline$ffr %>%
		
	
	
    
})
```

## Transform to Base Form
```{r}
local({
	
	res =
		purrr::imap(m$qual$predraw, function(x, .scenarioname)
			
			x %>%
				purrr::imap(., function(df, .varname) {
					
					transform = dplyr::filter(p$variablesDf, varname == .varname)[[df$form[[1]]]]
					fcDf = dplyr::select(df, -form)
					histDf = tail(dplyr::filter(na.omit(h$base$m[, c('date', .varname)]), date < min(fcDf$date)), 1) %>% setNames(., c('date', 'value'))
					
					fcDf %>%
						dplyr::mutate(
							.,
							varname = .varname,
							value := 
								{
			                        if (transform == 'dlog') undlog(fcDf$value, histDf$value)
									else if (transform == 'apchg') unapchg(fcDf$value, 12, histDf$value)
									else if (transform == 'pchg') unpchg(fcDf$value, histDf$value)
									else if (transform == 'base') .$value
									else stop('Err: ', .varname)
									}
								)
					
					}) %>%
				dplyr::bind_rows(.) %>%
				tidyr::pivot_wider(., names_from = 'varname', values_from = 'value') %>%
				dplyr::arrange(., date)
			
			)
	
	
	m$qual$predqual <<- res
})
```

## Add Calculated Variables
```{r}
local({
	
	# Calculate DNS
	lambda = m$dnsLambda
	
	# Rebuild yield curves with Diebold-Li function
	df =
		lapply(m$qual$predqual, function(scenario) {
			
			tDf = lapply(purrr::transpose(m$dnsYieldCurveNamesMap), function(y)
					scenario %>%
						dplyr::transmute(
							.,
							date,
							!!y$varname := ffr +
								tdns1 +
								tdns2 * (1-exp(-1 * lambda * y$ttm))/(lambda * y$ttm) +
								tdns3 * ((1-exp(-1 * lambda * y$ttm))/(lambda * y$ttm) - exp(-1 * lambda * y$ttm))
							)
					) %>%
				purrr::reduce(., function(x, y) dplyr::inner_join(x, y, by = 'date'))
			
			mortDf =
				dplyr::inner_join(scenario, tDf, by = 'date') %>%
				dplyr::transmute(., date, mort15y = mort15yt10yspread + t10y, mort30y = mort30yt30yspread + t30y) 
			
			list(tDf, mortDf) %>%
				purrr::reduce(., function(x, y) dplyr::inner_join(x, y, by = 'date')) %>%
				dplyr::arrange(., date)
			})
	
	

	
	m$qual$predcalc <<- df
})
```

## Join & Flatten 
```{r}
local({
	
	
	baseDfs =
		lapply(names(m$qual$predqual) %>% setNames(., .), function(scenarioname)
			dplyr::bind_rows(
				tidyr::pivot_longer(m$qual$predqual[[scenarioname]], -date, names_to = 'varname'),
				tidyr::pivot_longer(m$qual$predcalc[[scenarioname]], -date, names_to = 'varname')
				) %>%
				dplyr::bind_rows(.) %>%
				tidyr::pivot_wider(., names_from = 'varname', values_from = 'value') %>%
				dplyr::arrange(., date)
			)
	
	dfs =
		purrr::imap(baseDfs, function(scenarioDf, scenarioname)
			lapply(c('d1', 'st') %>% setNames(., .), function(.form)
				lapply(colnames(scenarioDf) %>% .[. != 'date'], function(.varname) {
						
						transform = dplyr::filter(p$variablesDf, varname == .varname)[[.form]]
						fcDf = dplyr::select(scenarioDf, all_of(c('date', .varname))) %>% na.omit(.)
						histDf = tail(dplyr::filter(na.omit(h$base$m[, c('date', .varname)]), date < min(fcDf$date)), 1)
						
						dplyr::bind_rows(histDf, fcDf) %>%
							dplyr::mutate(
								.,
								!!.varname := 
									{
				                        if (transform == 'dlog') dlog(.[[2]])
										else if (transform == 'apchg') apchg(.[[2]], 12)
										else if (transform == 'pchg') pchg(.[[2]])
										else if (transform == 'base') .[[2]]
										else if (transform == 'none') NA
										else stop('Err: ', .varname)
										}
									) %>% .[2:nrow(.),]
						
						}) %>%
					purrr::reduce(., function(x, y) dplyr::full_join(x, y, by = 'date')) %>%
					dplyr::arrange(., date)
			) %>%
			c(list(base = baseDfs[[scenarioname]]), .)
		) 
	
	
	predFlat =
		dfs %>%
		purrr::imap_dfr(., function(x, scenarioname)
			purrr::imap_dfr(x, function(y, form)
				y %>%
					tidyr::pivot_longer(., -date, names_to = 'varname', values_to = 'value') %>%
					dplyr::mutate(., form = form, scenarioname = scenarioname) %>%
					na.omit(.)
				)
			)
	

	m$qual$pred <<- dfs
	m$qual$predFlat <<- predFlat
})
```


# Evaluate and Combine

## Evaluate Pred Qual
```{r}
local({
	
	predCharts =
		m$qual$predFlat %>%
		dplyr::filter(., form == 'd1') %>%
		dplyr::group_by(., varname) %>%
		dplyr::group_split(.) %>%
		setNames(., sapply(., function(x) x$varname[[1]])) %>%
		lapply(., function(x) {
			
			param =
				p$variablesDf %>%
				dplyr::filter(., varname == x$varname[[1]]) %>%
				as.list(.)
			
			histDf = dplyr::transmute(p$variables[[param$varname]]$h$d1$m, date, value, type = 'Historical Data')
			
			forecastDf =
				dplyr::bind_rows(tail(histDf, 1), x) %>%
				dplyr::transmute(., date, value, type = 'Forecast')
 
			dplyr::bind_rows(histDf, forecastDf) %>%
				ggplot(.) +
				geom_line(aes(x = date, y = value, color = type, linetype = type)) +
				scale_color_manual(
					values = c('Historical Data' = 'black', 'Forecast' = 'Red')
				) +
				scale_linetype_manual(
					values = c('Historical Data' = 'solid', 'Forecast' = 'solid')
				) +
				labs(title = param$fullname, x = NULL, y = param$units, color = NULL, linetype = NULL) +
				ggthemes::theme_fivethirtyeight()
			})
	
	print(predCharts)
	
	m$qual$predCharts <<- predCharts
})
```


# Finalize

## Export
```{r}
local({
  
    saveRDS(
    	list(p = p, h = h, m = m),
    	str_glue(OUTPUT_DIR, '/[{p$VINTAGE_DATE}] m3.rds')
    	)
    
})
```