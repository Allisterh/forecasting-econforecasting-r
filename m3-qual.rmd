# Set Constants
```{r purl = TRUE}
DIR = 'D:/Onedrive/__Projects/econforecasting'
PACKAGE_DIR = 'D:/Onedrive/__Projects/econforecasting/r-package'
INPUT_DIR = 'D:/Onedrive/__Projects/econforecasting/model-inputs'
OUTPUT_DIR = 'D:/Onedrive/__Projects/econforecasting/model-outputs'
VINTAGE_DATE = '2021-08-27'
```

# Initialize
```{r}
# General purpose
library(tidyverse) # General
library(data.table) # General
library(devtools) # General
library(lubridate) # Dates
library(glue) # String Interpolation
# Data parse/import
library(jsonlite) # JSON Parser
library(rvest) # HTML Parser
library(httr) # CURL Interface
library(cowplot) # Join ggplots
# SQL/Apache Spark
library(DBI) # SQL Interface
# library(RPostgres) # PostgreSQL
# library(rsparklyr) # Spark
# My package
devtools::load_all(path = PACKAGE_DIR)
devtools::document(PACKAGE_DIR)
# library(econforecasting)

# Set working directory
setwd(DIR)

# Read constants
source(file.path(INPUT_DIR, 'constants.r'))
```

## Load RDS
```{r}
local({
	
	rds = readRDS(paste0(OUTPUT_DIR, '/[', VINTAGE_DATE, '] m2.rds'))

	p <<- rds$p
	m <<- rds$m
	h <<- rds$h
})
```



# Generate Initial Forecasts

## Rates
```{r}
local({

	rates = list(baseline = list(), downside = list())
	
	##### FFR #####
    rates$baseline$ffr =
        m$ext$sources$cme %>%
        dplyr::filter(., varname == 'ffr') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$ffr$h$base$m$date)) %>%
        dplyr::transmute(., freq, form, date, value)
    
    rates$downside$ffr =
        m$ext$sources$cme %>%
        dplyr::filter(., varname == 'ffr') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$ffr$h$base$m$date)) %>%
    	dplyr::mutate(
    		.,
    		value = ifelse(date >= as.Date('2022-06-01') & date <= as.Date('2022-12-01'), filter(., date == as.Date('2022-05-01'))$value, value),
			value = ifelse(date >= as.Date('2023-01-01') & date <= as.Date('2024-06-01'), NA, value)
    	) %>%
        dplyr::transmute(., freq, form, date, value) %>%
		dplyr::mutate(., value = zoo::na.approx(value))   
    
    
	##### SOFR #####
    rates$baseline$sofr =
        m$ext$sources$cme %>%
        dplyr::filter(., varname == 'sofr') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$sofr$h$base$m$date)) %>%
        dplyr::transmute(., freq, form, date, value)
    
    rates$downside$sofr =
        m$ext$sources$cme %>%
        dplyr::filter(., varname == 'sofr') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$sofr$h$base$m$date)) %>%
    	dplyr::mutate(
    		.,
    		value = ifelse(date >= as.Date('2022-06-01') & date <= as.Date('2022-12-01'), filter(., date == as.Date('2022-05-01'))$value, value),
			value = ifelse(date >= as.Date('2023-01-01') & date <= as.Date('2024-06-01'), NA, value)
    	) %>%
        dplyr::transmute(., freq, form, date, value) %>%
		dplyr::mutate(., value = zoo::na.approx(value))   
    
    
    ##### INF #####

    rates$baseline$inf =
        m$ext$sources$cle %>%
        dplyr::filter(., varname == 'inf') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$inf$h$base$m$date)) %>%
        dplyr::transmute(., freq, form, date, value)
    
    
    rates$downside$inf =
        m$ext$sources$cle %>%
        dplyr::filter(., varname == 'inf') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$inf$h$base$m$date)) %>%
    	dplyr::mutate(
    		.,
    		value = ifelse(date == as.Date('2022-01-01'), value - .2, value),
    		value = ifelse(date >= as.Date('2022-02-01') & date <= as.Date('2022-06-01'), NA, value),
    		value = ifelse(date == as.Date('2022-07-01'), value - .3, value),
    		value = ifelse(date >= as.Date('2022-08-01') & date <= as.Date('2023-01-01'), NA, value)
    	) %>%
    	dplyr::mutate(., value = zoo::na.spline(value, method = 'natural'), form = 'd1', freq = 'm') %>%
        dplyr::transmute(., freq, form, date, value)

    
    ##### TDNS1 #####
    
    rates$baseline$tdns1 =
        m$ext$sources$dns %>%
        dplyr::filter(., varname == 'tdns1') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$tdns1$h$base$m$date)) %>%
        dplyr::transmute(., freq, form, date, value)
    
    rates$downside$tdns1 =
        m$ext$sources$dns %>%
        dplyr::filter(., varname == 'tdns1') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$tdns1$h$base$m$date)) %>%
    	dplyr::mutate(
    		.,
    		value = ifelse(date == as.Date('2022-01-01'), value - .1, value),
    		value = ifelse(date >= as.Date('2022-02-01') & date <= as.Date('2022-06-01'), NA, value),
    		value = ifelse(date == as.Date('2022-07-01'), value - .1, value),
    		value = ifelse(date >= as.Date('2022-08-01') & date <= as.Date('2023-01-01'), NA, value)
    	) %>%
    	dplyr::mutate(., value = zoo::na.spline(value, method = 'natural')) %>%
        dplyr::transmute(., freq, form, date, value)
    
    
    ##### TDNS2 #####

    rates$baseline$tdns2 =
        m$ext$sources$dns %>%
        dplyr::filter(., varname == 'tdns2') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$tdns2$h$base$m$date)) %>%
        dplyr::transmute(., freq, form, date, value)
    
    
    rates$downside$tdns2 =
        m$ext$sources$dns %>%
        dplyr::filter(., varname == 'tdns2') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$tdns2$h$base$m$date)) %>%
    	dplyr::mutate(
    		.,
    		value = ifelse(date == as.Date('2022-01-01'), value + .2, value),
    		value = ifelse(date >= as.Date('2022-02-01') & date <= as.Date('2022-06-01'), NA, value),
    		value = ifelse(date == as.Date('2022-07-01'), value + .3, value),
    		value = ifelse(date >= as.Date('2022-08-01') & date <= as.Date('2023-01-01'), NA, value)
    	) %>%
    	dplyr::mutate(., value = zoo::na.spline(value, method = 'natural')) %>%
        dplyr::transmute(., freq, form, date, value)

    
    ##### TDNS3 #####

    rates$baseline$tdns3 =
        m$ext$sources$dns %>%
        dplyr::filter(., varname == 'tdns3') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$tdns3$h$base$m$date)) %>%
        dplyr::transmute(., freq, form, date, value)
	
	
    rates$downside$tdns3 =
        m$ext$sources$dns %>%
        dplyr::filter(., varname == 'tdns3') %>%
        dplyr::filter(., vdate == max(vdate)) %>%
        dplyr::filter(., date > max(p$variables$tdns3$h$base$m$date)) %>%
    	dplyr::mutate(., value = zoo::na.spline(value, method = 'natural')) %>%
        dplyr::transmute(., freq, form, date, value)


    ##### MORT15Y10YSPREAD #####
    # Direction of spread is almost always exactly in the opposite direction of t10y/2
	# dplyr::inner_join(p$variables$mort15yt10yspread$h$d1$m, p$variables$t10y$h$d1$m, by = 'date') %>%
	# ggplot(.) + geom_line(aes(x = date, y = value.x)) + geom_line(aes(x = date, y = value.y))
    
    rates$baseline$mort15yt10yspread =
    	# Get change in tdns1
    	dplyr::bind_rows(
    		p$variables$tdns1$h$d1$m,
    		rates$baseline$tdns1 %>% dplyr::select(., -form)
    		) %>%
    	dplyr::mutate(., value = (value - dplyr::lag(value, 1))) %>%
    	# Scale to appropriate change desired in mort15y10yspread
    	dplyr::mutate(., value = value * -1/4) %>%
    	# Now undifference to get forecast for mortspread
    	dplyr::filter(., date > max(p$variables$mort15yt10yspread$h$d1$m$date)) %>%
    	dplyr::mutate(., value = undiff(value, 1, tail(p$variables$mort15yt10yspread$h$d1$m, 1)$value), form = 'd1') %>%
    	dplyr::mutate(., freq = 'm')
    
    rates$downside$mort15yt10yspread =
    	# Get change in tdns1
    	dplyr::bind_rows(
    		p$variables$tdns1$h$d1$m,
    		rates$downside$tdns1 %>% dplyr::select(., -form)
    		) %>%
    	dplyr::mutate(., value = (value - dplyr::lag(value, 1))) %>%
    	# Scale to appropriate change desired in mort15y10yspread
    	dplyr::mutate(., value = value * -1/4) %>%
    	# Now undifference to get forecast for mortspread
    	dplyr::filter(., date > max(p$variables$mort15yt10yspread$h$d1$m$date)) %>%
    	dplyr::mutate(., value = undiff(value, 1, tail(p$variables$mort15yt10yspread$h$d1$m, 1)$value), form = 'd1') %>%
    	dplyr::mutate(., freq = 'm')

    
    
    ##### MORT30YT30YSPREAD #####

    rates$baseline$mort30yt30yspread =
    	# Get change in tdns1
    	dplyr::bind_rows(
    		p$variables$tdns1$h$d1$m,
    		rates$baseline$tdns1 %>% dplyr::select(., -form)
    		) %>%
    	dplyr::mutate(., value = (value - dplyr::lag(value, 1))) %>%
    	# Scale to appropriate change desired in mort15y10yspread
    	dplyr::mutate(., value = value * -1/4) %>%
    	# Now undifference to get forecast for mortspread
    	dplyr::filter(., date > max(p$variables$mort30yt30yspread$h$d1$m$date)) %>%
    	dplyr::mutate(., value = undiff(value, 1, tail(p$variables$mort30yt30yspread$h$d1$m, 1)$value), form = 'd1') %>%
    	dplyr::mutate(., freq = 'm')

    
    rates$downside$mort30yt30yspread =
    	# Get change in tdns1
    	dplyr::bind_rows(
    		p$variables$tdns1$h$d1$m,
    		rates$downside$tdns1 %>% dplyr::select(., -form)
    		) %>%
    	dplyr::mutate(., value = (value - dplyr::lag(value, 1))) %>%
    	# Scale to appropriate change desired in mort15y10yspread
    	dplyr::mutate(., value = value * -1/4) %>%
    	# Now undifference to get forecast for mortspread
    	dplyr::filter(., date > max(p$variables$mort30yt30yspread$h$d1$m$date)) %>%
    	dplyr::mutate(., value = undiff(value, 1, tail(p$variables$mort30yt30yspread$h$d1$m, 1)$value), form = 'd1') %>%
    	dplyr::mutate(., freq = 'm')

    
    
    
	m$qual$init$rates <<- rates
})
```

## Consumer Sector
```{r}
local({
	
	consumer = list(baseline = list(), downside = list())

	##### PID #####
    # Use nowcast -> slice with moving average
    consumer$baseline$pid =
		m$ncpred$d1$m[, c('date', 'pid')] %>%
    	na.omit(.) %>%
    	dplyr::rename(., value = 'pid') %>%
    	dplyr::transmute(., date, value) %>%
    	# Only take first row from nowcast and replace with 1
    	head(., 1) %>%
    	dplyr::mutate(., value = ifelse(date == min(date), 8.0, value)) %>%
        dplyr::bind_rows(
            .,
            tribble(
            	~ 'date', ~ 'value',
            	as.Date('2022-04-01'), 5.00,
            	as.Date('2022-07-01'), 5.00,
            	as.Date('2023-10-01'), 3.50,
            	as.Date('2028-10-01'), 3.50,
            )
        ) %>%
    	dplyr::left_join(
    		tibble(date = seq(from = min(.$date), to = max(.$date), by = '1 month')),
    		.,
    		by = 'date'
    	) %>%
    	dplyr::mutate(., value = zoo::na.approx(value), form = 'd1', freq = 'm')

    
    consumer$downside$pid =
		m$ncpred$d1$m[, c('date', 'pid')] %>%
    	na.omit(.) %>%
    	dplyr::rename(., value = 'pid') %>%
    	dplyr::transmute(., date, value) %>%
        dplyr::bind_rows(
            .,
            tribble(
            	~ 'date', ~ 'value',
            	as.Date('2022-04-01'), 4.00,
            	as.Date('2022-07-01'), 4.00,
            	as.Date('2023-10-01'), 2.50,
            	as.Date('2028-10-01'), 3.00,
            )
        ) %>%
    	dplyr::left_join(
    		tibble(date = seq(from = min(.$date), to = max(.$date), by = '1 month')),
    		.,
    		by = 'date'
    	) %>%
    	dplyr::mutate(., value = zoo::na.approx(value), form = 'd1', freq = 'm')

    

    ##### UE #####
    consumer$baseline$ue =
        # Take last four quarters of historical data
        p$variables$ue$h$base$m %>%
        tail(., 4) %>%
        dplyr::transmute(., form = 'd1', date, value) %>%
        # Bind next 24 months
        dplyr::bind_rows(
            .,
            tibble(
                form = 'd1',
                date = seq(from = lubridate::add_with_rollback(tail(.$date, 1), months(1)), by = '1 month', length.out = 60)
                )
            ) %>%
        # # Now join with external forecast, but use historical data if external forecast has same dates
        # dplyr::left_join(
        #     .,
        #     m$ext$sources$spf %>%
        #         dplyr::filter(., vdate == max(vdate) & varname == 'ue') %>%
        #         dplyr::transmute(., form, date, value2 = value),
        #     by = c('form', 'date')
        # ) %>%
        # dplyr::mutate(., value = ifelse(!is.na(value), value, value2)) %>%
    	# dplyr::select(., -value2) %>%
        # Add in long run average
        dplyr::mutate(., value = ifelse(date == max(date), 4.5, value)) %>%
        dplyr::mutate(., value = ifelse(date == '2021-10-01', 5.2, value)) %>%
        dplyr::mutate(., value = ifelse(date == '2022-01-01', 4.8, value)) %>%
        dplyr::mutate(., value = ifelse(date == '2023-01-01', 4.3, value)) %>%
        dplyr::mutate(., value = ifelse(date == '2024-01-01', 4.4, value)) %>%
        # Splinal interpolate
        dplyr::mutate(., value = zoo::na.spline(value, method = 'natural')) %>% # Linear, monoH.FC
        tail(., -4) %>%
    	dplyr::mutate(., freq = 'm')
    
    # Display in website
    consumer$downside$ue =
        # Take last four quarters of historical data
        p$variables$ue$h$base$m %>%
        tail(., 4) %>%
        dplyr::transmute(., form = 'd1', date, value) %>%
        # Bind next 24 months
        dplyr::bind_rows(
            .,
            tibble(
                form = 'd1',
                date = seq(from = lubridate::add_with_rollback(tail(.$date, 1), months(1)), by = '1 month', length.out = 60)
                )
            ) %>%
        # Add in long run average
        dplyr::mutate(., value = ifelse(date == max(date), 4.5, value)) %>%
        dplyr::mutate(., value = ifelse(date == '2021-10-01', 5.2, value)) %>%
        dplyr::mutate(., value = ifelse(date == '2022-01-01', 5.3, value)) %>%
        dplyr::mutate(., value = ifelse(date == '2023-01-01', 5.0, value)) %>%
        dplyr::mutate(., value = ifelse(date == '2024-01-01', 5.0, value)) %>%
        # Splinal interpolate
        dplyr::mutate(., value = zoo::na.spline(value, method = 'natural')) %>% # Linear, monoH.FC
        tail(., -4) %>%
    	dplyr::mutate(., freq = 'm')

    
	m$qual$init$consumer <<- consumer
})
```

## Asset Prices
```{r}
local({
	
	assets = list(baseline = list(), downside = list())
	
	##### HPI #####
    assets$baseline$hpi =
		m$ncpred$d1$m[, c('date', 'hpi')] %>%
    	na.omit(.) %>%
    	dplyr::rename(., value = 'hpi') %>%
    	dplyr::transmute(., date, value) %>%
        dplyr::bind_rows(
            .,
            tribble(
            	~ 'date', ~ 'value',
            	as.Date('2022-04-01'), 3.50,
            	as.Date('2022-07-01'), 3.00,
            	as.Date('2023-10-01'), 2.50,
            	as.Date('2028-10-01'), 2.50,
            )
        ) %>%
    	dplyr::left_join(
    		tibble(date = seq(from = min(.$date), to = max(.$date), by = '1 month')),
    		.,
    		by = 'date'
    	) %>%
    	dplyr::mutate(., value = zoo::na.approx(value), form = 'd1') %>%
    	dplyr::mutate(., freq = 'm')
    
	assets$downside$hpi =
		m$ncpred$d1$m[, c('date', 'hpi')] %>%
    	na.omit(.) %>%
    	dplyr::rename(., value = 'hpi') %>%
    	dplyr::transmute(., date, value) %>%
        dplyr::bind_rows(
            .,
            tribble(
            	~ 'date', ~ 'value',
            	as.Date('2022-04-01'), 2.00,
            	as.Date('2022-07-01'), 4.00,
            	as.Date('2023-10-01'), 3.50,
            	as.Date('2028-10-01'), 2.50,
            )
        ) %>%
    	dplyr::left_join(
    		tibble(date = seq(from = min(.$date), to = max(.$date), by = '1 month')),
    		.,
    		by = 'date'
    	) %>%
    	dplyr::mutate(., value = zoo::na.approx(value), form = 'd1') %>%
    	dplyr::mutate(., freq = 'm')

	
    ##### SPY #####
    assets$baseline$spy =
		m$ncpred$d1$m[, c('date', 'spy')] %>%
    	na.omit(.) %>%
    	dplyr::rename(., value = 'spy') %>%
    	dplyr::transmute(., date, value) %>%
        dplyr::bind_rows(
            .,
            tribble(
            	~ 'date', ~ 'value',
            	as.Date('2023-04-01'), 1.00,
            	as.Date('2024-04-01'), 1.00,
            	as.Date('2025-04-01'), 0.90,
            	as.Date('2026-04-01'), 0.90
            )
        ) %>%
    	dplyr::left_join(
    		tibble(date = seq(from = min(.$date), to = max(.$date), by = '1 month')),
    		.,
    		by = 'date'
    	) %>%
    	dplyr::mutate(., value = zoo::na.approx(value), form = 'd1') %>%
    	dplyr::mutate(., freq = 'm')
	
	
    assets$downside$spy =
		m$ncpred$d1$m[, c('date', 'spy')] %>%
    	na.omit(.) %>%
    	dplyr::rename(., value = 'spy') %>%
    	dplyr::transmute(., date, value) %>%
        dplyr::bind_rows(
            .,
            tribble(
            	~ 'date', ~ 'value',
            	as.Date('2023-04-01'), -.1,
            	as.Date('2024-04-01'), 0.9,
            	as.Date('2025-04-01'), 0.90,
            	as.Date('2026-04-01'), 0.90
            )
        ) %>%
    	dplyr::left_join(
    		tibble(date = seq(from = min(.$date), to = max(.$date), by = '1 month')),
    		.,
    		by = 'date'
    	) %>%
    	dplyr::mutate(., value = zoo::na.approx(value), form = 'd1') %>%
    	dplyr::mutate(., freq = 'm')

    

	m$qual$init$assets <<- assets
})
```

## Partially Exogenous
```{r}
local({
	
	partial = list(baseline = list(), downside = list())

	# PARTIAL LENGTH FORECASTS
    
    # Have first four quarters of PCE, gross_pdi, etc. be exogenous in data
    ncList = c(
    	'pcegdmotor', 'pcegdfurnish', 'pcegdrec', 'pcegdother',
    	'pcegnfood', 'pcegnclothing', 'pcegngas', 'pcegnother',
    	'pceshousing', 'pceshealth', 'pcestransport', 'pcesrec', 'pcesfood', 'pcesfinal',
    	'pcesother', 'pcesnonprofit',
    	'pdinstruct', 'pdinequip', 'pdinip', 'pdir',
    	'exg', 'exs', 'img', 'ims', 'govt', 'govts'
    	)
    
    ncForecasts =
    	m$ncpredFlat %>%
    	dplyr::filter(., freq == 'q' & varname %in% ncList & form == 'd1' & vdate == max(vdate)) %>%
    	dplyr::group_by(., varname) %>%
    	econforecasting::namedSplit(.) %>%
    	lapply(., function(df)
    		df %>%
    			dplyr::select(., freq, form, date, value)
    		)

    if (all(sort(names(ncForecasts)) != sort(ncList))) stop('Error: missing nowcasted variable')

    partial$baseline = ncForecasts
	partial$downside = ncForecasts
	
	m$qual$init$partial <<- partial
})
```

## Combine & Aggregate
```{r}
local({
	
	scenarionames = m$qual$init %>% sapply(., function(x) names(x)) %>% c(.) %>% unique(.)
	
	predraw = lapply(scenarionames %>% setNames(., .), function(scenarioname)
		lapply(m$qual$init, function(x) x[[scenarioname]]) %>% unname(.) %>% unlist(., recursive = F)
		)

	m$qual$predraw <<- predraw	
})
```


# Transforms

## Detransform to Base Form
```{r}
local({
	
	res = purrr::imap(m$qual$predraw, function(x, .scenarioname) {
			
		purrr::imap(x, function(df, .varname) {
			
			.freq = df$freq[[1]]
			transform = dplyr::filter(p$variablesDf, varname == .varname)[[df$form[[1]]]]
			fcDf = dplyr::select(df, -form)
			histDf =
				h$flat %>%
				dplyr::filter(., varname == .varname, date < min(fcDf$date), freq == .freq, form == 'base') %>%
				tail(., 1) %>%
				dplyr::select(., freq, date, value)
				
			fcDf %>%
				dplyr::mutate(
					.,
					varname = .varname,
					value := {
                        if (transform == 'dlog') undlog(fcDf$value, histDf$value)
						else if (transform == 'apchg') unapchg(fcDf$value, {if (.freq == 'm') 12 else 4}, histDf$value)
						else if (transform == 'pchg') unpchg(fcDf$value, histDf$value)
						else if (transform == 'base') .$value
						else stop('Err: ', .varname)
						}
					)
				}) %>%
			dplyr::bind_rows(.)
		})
	
	
	m$qual$predqual <<- res
})
```

## Add calculated variables
```{r}
local({
	
	# Calculate DNS
	lambda = m$dnsLambda
	
	# Rebuild yield curves with Diebold-Li function
	df =
		lapply(m$qual$predqual, function(df) {
			
			scenario =
				df %>% dplyr::filter(., freq == 'm') %>%
				dplyr::select(., -freq) %>%
				tidyr::pivot_wider(., names_from = 'varname', values_from = 'value') %>%
				dplyr::arrange(., date)
			
			tDf = lapply(purrr::transpose(m$dnsYieldCurveNamesMap), function(y)
					scenario %>%
						dplyr::transmute(
							.,
							date,
							!!y$varname := ffr +
								tdns1 +
								tdns2 * (1-exp(-1 * lambda * y$ttm))/(lambda * y$ttm) +
								tdns3 * ((1-exp(-1 * lambda * y$ttm))/(lambda * y$ttm) - exp(-1 * lambda * y$ttm))
							)
					) %>%
				purrr::reduce(., function(x, y) dplyr::inner_join(x, y, by = 'date'))
			
			mortDf =
				dplyr::inner_join(scenario, tDf, by = 'date') %>%
				{lapply(colnames(.) %>% .[. != 'date'], function(.varname) {
					dplyr::select(., all_of(c('date', .varname))) %>%
						na.omit(.) %>%
						dplyr::bind_rows(
							filter(na.omit(h$base$m[, c('date', .varname)]), date <= tail(.$date[[1]])),
							.
						)
				})} %>%
				purrr::reduce(., function(x, y) dplyr::full_join(x, y, by = 'date')) %>%
				dplyr::arrange(., date) %>%
				dplyr::transmute(., date, mort15y = mort15yt10yspread + t10y, mort30y = mort30yt30yspread + t30y) %>%
				{lapply(colnames(.) %>% .[. != 'date'], function(.varname) {
					dplyr::select(., all_of(c('date', .varname))) %>%
						dplyr::filter(., date >= tail(na.omit(h$base$m[, c('date', .varname)])$date, 1))
				})} %>%
				purrr::reduce(., function(x, y) dplyr::full_join(x, y, by = 'date')) %>%
				dplyr::arrange(., date)

			list(tDf, mortDf) %>%
				purrr::reduce(., function(x, y) dplyr::full_join(x, y, by = 'date')) %>%
				dplyr::arrange(., date)
			})

	
	m$qual$predcalcM <<- df
})
```


## Add quarterly calculated
```{r}
local({
	
	# Rebuild yield curves with Diebold-Li function
	df =
		lapply(m$qual$predqual, function(df) {
			
			scenario =
				m$qual$predqual[[1]] %>% dplyr::filter(., freq == 'q') %>%
				dplyr::select(., -freq) %>%
				tidyr::pivot_wider(., names_from = 'varname', values_from = 'value') %>%
				dplyr::arrange(., date)
			
			scenario %>%
				dplyr::transmute(
					.,
					date
				)
			})

	
	m$qual$predcalcQ <<- df
})
```


# Calculate base forecasts

## Get final monthly
```{r}
local({
	
	res = lapply(names(m$qual$predqual) %>% setNames(., .), function(.scenarioname) {
		
		dplyr::bind_rows(
			m$qual$predqual[[.scenarioname]] %>%
				dplyr::filter(., freq == 'm') %>%
				dplyr::select(., -freq),
			m$qual$predcalcM[[.scenarioname]] %>%
				tidyr::pivot_longer(., -date, names_to = 'varname', values_to = 'value', values_drop_na = TRUE)
			)
	})
	

	m$qual$predFinalM <<- res
})
```


## Get initial quarterly
```{r}
local({
	
	res = lapply(names(m$qual$predqual) %>% setNames(., .), function(.scenarioname) {
		
		dplyr::bind_rows(
			m$qual$predqual[[.scenarioname]] %>%
				dplyr::filter(., freq == 'q') %>%
				dplyr::select(., -freq)#,
			# m$qual$predcalcQ[[.scenarioname]] %>%
			# 	tidyr::pivot_longer(., -date, names_to = 'varname', values_to = 'value', values_drop_na = TRUE)
			)
	})
	
	m$qual$predInitialQ <<- res
})
```

## Aggregate monthly to quarterly
```{r}
local({
	
	# Get exogenous qualitative forecasts
	qualDfs = m$qual$predFinalM
	

	# Iterate through scenarios, combine and aggregate to quarterly
	aggDfs = lapply(qualDfs, function(qualDf) {
		
		# Get historical Df
		histDf =
			h$flat %>%
			dplyr::filter(., freq == 'm' & varname %in% unique(qualDf$varname) & form == 'base') %>%
			dplyr::select(., date, value, varname)
		
		res = lapply(unique(qualDf$varname), function(.varname) {

			hDf = histDf %>% dplyr::filter(., varname == .varname)
			qDf = qualDf %>% dplyr::filter(., varname == .varname)
			
			dplyr::bind_rows(hDf, qDf) %>%
				dplyr::arrange(., date) %>%
				dplyr::mutate(., strdate = paste0(year(date), 'Q', quarter(date))) %>%
				dplyr::group_by(., strdate) %>%
				dplyr::group_split(.) %>%
			    lapply(., function(y) {
			        if (nrow(y) >= 3) tibble(varname = y$varname[[1]], value = mean(y$value), strdate = y$strdate[[1]])
			        else if (nrow(y) < 3) NA
			        else stop('Error: qDf has same varname/date combination as hDf')
			    }) %>%
				purrr::keep(., function(x) is_tibble(x)) %>%
				dplyr::bind_rows(.) %>%
				dplyr::mutate(., date = econforecasting::strdateToDate(strdate)) %>%
				dplyr::select(., -strdate) %>%
				dplyr::arrange(., date) %>%
				dplyr::filter(., date >= lubridate::floor_date(qDf$date[[1]], unit = 'quarters'))
			}) %>%
			dplyr::bind_rows(.)
		
		return(res)
		})
	
	## Bind to existing quarterly forecasts
	qDfs = lapply(names(qualDfs) %>% setNames(., .), function(.scenarioname) {
		
		dplyr::bind_rows(
			aggDfs[[.scenarioname]],
			m$qual$predInitialQ[[.scenarioname]]
			) %>%
			tidyr::pivot_wider(., names_from = 'varname', values_from = 'value') %>%
			dplyr::arrange(., date) %>%
			tidyr::pivot_longer(., -date, names_to = 'varname', values_to = 'value', values_drop_na = TRUE)
	})


	m$qual$predFinalQ <<- qDfs
})
```


# Transform and Join

## Transformations
```{r}
local({

	# Transform base forms to alt forms
	mDf = purrr::imap(m$qual$predFinalM, function(scenarioDf, scenarioname)
		lapply(c('st', 'd1', 'd2') %>% setNames(., .), function(.form)
			lapply(unique(scenarioDf$varname) %>% setNames(., .), function(.varname) {
				transform = dplyr::filter(p$variablesDf, varname == .varname)[[.form]]
				fcDf = dplyr::filter(scenarioDf, varname == .varname)
				histDf = 
					h$flat %>%
					dplyr::filter(., freq == 'm' & varname == .varname & form == 'base' & date < max(fcDf$date)) %>%
					dplyr::select(., date, value, varname) %>%
					dplyr::filter(., date == max(date))

				dplyr::bind_rows(histDf, fcDf) %>%
					{tibble(
						date = .$date,
						varname = .$varname,
						form = .form,
						value := {
	                        if (transform == 'dlog') dlog(.$value)
							else if (transform == 'apchg') apchg(.$value, 12)
							else if (transform == 'diff1') diff(.$value, 1)
							else if (transform == 'pchg') pchg(.$value)
							else if (transform == 'base') .$value
							else if (transform == 'none') NA
							else stop('Err: ', .varname, ' | ', .form)
						}
					)} %>%
					.[2:nrow(.),]
				}) %>%
				dplyr::bind_rows(.)
			) %>%
			c(list(base = dplyr::mutate(m$qual$predFinalM[[scenarioname]], form = 'base')), .)
		) %>%
		purrr::imap_dfr(., function(dfs, .scenarioname)
			dfs %>%
				dplyr::bind_rows(.) %>%
				dplyr::transmute(., scenarioname = .scenarioname, freq = 'm', form, date, varname, value)
			)
	
	
	qDf = purrr::imap(m$qual$predFinalQ, function(scenarioDf, scenarioname)
		lapply(c('st', 'd1', 'd2') %>% setNames(., .), function(.form)
			lapply(unique(scenarioDf$varname) %>% setNames(., .), function(.varname) {
				transform = dplyr::filter(p$variablesDf, varname == .varname)[[.form]]
				fcDf = dplyr::filter(scenarioDf, varname == .varname)
				histDf = 
					h$flat %>%
					dplyr::filter(., freq == 'q' & varname == .varname & form == 'base' & date < max(fcDf$date)) %>%
					dplyr::select(., date, value, varname) %>%
					dplyr::filter(., date == max(date))

				dplyr::bind_rows(histDf, fcDf) %>%
					{tibble(
						date = .$date,
						varname = .$varname,
						form = .form,
						value := {
	                        if (transform == 'dlog') dlog(.$value)
							else if (transform == 'apchg') apchg(.$value, 4)
							else if (transform == 'diff1') diff(.$value, 1)
							else if (transform == 'pchg') pchg(.$value)
							else if (transform == 'base') .$value
							else if (transform == 'none') NA
							else stop('Err: ', .varname)
						}
					)} %>%
					.[2:nrow(.),]
				}) %>%
				dplyr::bind_rows(.)
			) %>%
			c(list(base = dplyr::mutate(m$qual$predFinalQ[[scenarioname]], form = 'base')), .)
		) %>%
		purrr::imap_dfr(., function(dfs, .scenarioname)
			dfs %>%
				dplyr::bind_rows(.) %>%
				dplyr::transmute(., scenarioname = .scenarioname, freq = 'q', form, date, varname, value)
			)
	

	res =
		dplyr::bind_rows(mDf, qDf) %>%
		na.omit(.)

	
	m$qual$predFlat <<- res
})
```

## Create wide forecasts
```{r}
local({
	
	dfs =
		m$qual$predFlat %>%
		as.data.table(.) %>%
		split(., by = c('scenarioname', 'form', 'freq'), keep.by = FALSE, flatten = FALSE) %>%
		lapply(., function(x)
			lapply(x, function(y)
				lapply(y, function(z)
					as_tibble(z) %>%
						tidyr::pivot_wider(., names_from = 'varname', values_from = 'value') %>%
						dplyr::arrange(., date)
					)
				)
			)
	

	m$qual$pred <<- dfs
})
```


# Evaluation

## Evaluate Pred Qual
```{r}
local({
	
	predCharts =
		m$qual$predFlat %>%
		dplyr::group_by(., varname) %>%
		econforecasting::namedSplit(.) %>%
		lapply(., function(x) {
			
			# message(x$varname[[1]])
			param =
				p$variablesDf %>%
				dplyr::filter(., varname == x$varname[[1]]) %>%
				as.list(.)
			
			plots =
				purrr::cross(list(freq = c('q', 'm'), form = c('d1', 'd2'))) %>%
				setNames(., map_chr(., ~ paste0(.$form, '.', .$freq))) %>%
				lapply(., function(y) {
					
					# message(y$form, ';', y$freq)
					if (y$freq == 'm' && param$freq == 'q') return(NULL)
					if (param[[y$form]] == 'none') return(NULL)

					transform = param[[y$form]]
					unitname = {
						if (transform == 'apchg') 'Annualized % Chg'
						else if (transform == 'pchg') 'Pct Chg'
						else if (transform == 'dlog') 'Log-Difference'
						else if (transform == 'base') param$units
						else if (transform == 'none') 'None'
						else stop ('Add transform type')
					}
					
					histDf = 
						h$flat %>%
						dplyr::filter(., freq == y$freq, form == y$form, varname == param$varname) %>%
						dplyr::arrange(., date) %>%
						dplyr::transmute(., date, value, type = 'historical')

					forecastDf =
						x %>%
						dplyr::filter(., freq == y$freq & form == y$form) %>%
						dplyr::group_by(scenarioname) %>%
						dplyr::group_split(.) %>%
						purrr::map_dfr(., function(z)
							dplyr::bind_rows(mutate(tail(histDf, 1), scenarioname = unique(z$scenarioname)), z)
							) %>%
						dplyr::transmute(., date, value, type = scenarioname)
					
					dplyr::bind_rows(histDf, forecastDf) %>%
						ggplot(.) +
						geom_line(aes(x = date, y = value, color = type)) +
						geom_point(aes(x = date, y = value, color = type)) +
						scale_color_manual(
							values = c('historical' = 'black', 'baseline' = 'red', 'downside' = 'blue')
						) +
						scale_linetype_manual(
							values = c('historical' = 'solid', 'baseline' = 'solid', 'downside' = 'blue')
						) +
						labs(
							subtitle = paste0({if (y$freq == 'q') 'Quarterly' else 'Monthly'}, ' Forecast'),
							x = NULL, y = unitname, color = NULL, linetype = NULL
							) +
						theme_gray(base_size = 12) +
						theme(axis.title = element_text(size = 10), axis.title.y = element_text(size = 10))
					}) %>%
				purrr::keep(., ~ !is.null(.) && nrow(.$data) > 0)

			title =
				cowplot::ggdraw() +
				cowplot::draw_label(param$fullname, fontface = 'bold', x = 0, hjust = 0) +
				theme(plot.margin = margin(0, 0, 0, 20))
			
			
			col1 =  {
				if (!is.null(plots$d1.q) && !is.null(plots$d2.q))
					cowplot::plot_grid(
						plots$d1.q + theme(legend.position = 'none'),
						plots$d2.q + theme(legend.position = 'none'),
						ncol = 1,
						rel_heights = c(1, .8)
						)
				else if (!is.null(plots$d1.q))
					cowplot::plot_grid(plots$d1.q + theme(legend.position = 'none'), ncol = 1)
				else
					NULL
				}
					
			col2 =  {
				if (!is.null(plots$d1.m) && !is.null(plots$d2.m))
					cowplot::plot_grid(
						plots$d1.m + theme(legend.position = 'none'),
						plots$d2.m + theme(legend.position = 'none'),
						ncol = 1,
						rel_heights = c(1, .8)
						)
				else if (!is.null(plots$d1.m))
					cowplot::plot_grid(plots$d1.m + theme(legend.position = 'none'), ncol = 1)
				else
					NULL
			}
			
			plotArea = {
				if (!is.null(col1) && !is.null(col2)) cowplot::plot_grid(col1, col2, nrow = 1)
				else if (!is.null(col1)) cowplot::plot_grid(col1, nrow = 1)
				else stop('None')
			}
			
			cowplot::plot_grid(
				title,
				plotArea,
				cowplot::get_legend(plots[[1]] + guides(color = guide_legend(nrow = 1))),
				nrow = 3,
				rel_heights = c(.15, 1, .1)
			)
			

			})
	
	print(predCharts)
	
	purrr::imap(predCharts, function(x, i)
		ggsave(
			file.path(OUTPUT_DIR, paste0('qual_', i, '.png')),
			plot = x, scale = 2.5, width = 4, height = 3, units = 'in'
			)
		)
	
	m$qual$predCharts <<- predCharts
})
```


# Finalize

## Export
```{r}
local({
  
    saveRDS(
    	list(p = p, h = h, m = m),
    	str_glue(OUTPUT_DIR, '/[{p$VINTAGE_DATE}] m3.rds')
    	)
    
})
```